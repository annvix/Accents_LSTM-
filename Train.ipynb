{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annvix/Accents_LSTM-/blob/master/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0HgBVexUeCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "388a3577-8e70-45e9-c512-1fd7e64762ad"
      },
      "source": [
        "!git clone https://github.com/annvix/Accents_LSTM-.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Accents_LSTM-'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 20 (delta 6), reused 17 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UZBhAnXUeCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# read data from dataset\n",
        "with open('Accents_LSTM-/Data.csv', 'r') as f:\n",
        "#with open('Data.csv', 'r') as f:\n",
        "    all_accents = f.readlines()\n",
        "data_len = len(all_accents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkmAredFUeCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words, accents = [], []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FywA8d6PUeCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(data_len):\n",
        "    str = all_accents[i].replace('\\n', '').split(',')\n",
        "    words.append(str[0])\n",
        "    accents.append(str[1])\n",
        "max_len = len(max(words, key=len))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJZjABorUeCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a19fab89-db0b-4e9b-e33c-321b1d09c81c"
      },
      "source": [
        "print('Max word length:')\n",
        "print(max_len)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max word length:\n",
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5y-ehgKUeCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_int = np.zeros((data_len,max_len), dtype=int)\n",
        "accents_int = np.zeros(data_len, dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WPFFu4qUeCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(data_len):\n",
        "    for j in range(len(words[i])):\n",
        "        words_int[i][j]=ord(words[i][j])\n",
        "    accents_int[i] = accents[i].find(chr(39)) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIunFyqhUeCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "fe60ba4b-7613-48d3-dc3c-d8e9b87c7867"
      },
      "source": [
        "print('Words without accents:')\n",
        "for i in range(len(words)):\n",
        "    if accents_int[i]==0:\n",
        "        print(words[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words without accents:\n",
            "б\n",
            "брр\n",
            "в\n",
            "гм\n",
            "ж\n",
            "к\n",
            "кш\n",
            "ль\n",
            "мм\n",
            "с\n",
            "тсс\n",
            "хм\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRa-Hc8qUeCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_frac = 0.8\n",
        "val_frac = 0.1\n",
        "test_frac = 0.1\n",
        "\n",
        "\n",
        "def train_test_val_words(words_int):\n",
        "    return (words_int[:int(len(words_int)*train_frac)], \n",
        "words_int[int(len(words_int)*train_frac) : (int(len(words_int)*train_frac) + int(len(words_int)*val_frac))], \n",
        "words_int[(int(len(words_int)*train_frac) + int(len(words_int)*val_frac)):])\n",
        "    \n",
        "def train_test_val_accents(accents_int):\n",
        "    return (accents_int[:int(len(accents_int)*train_frac)], \n",
        "accents_int[int(len(accents_int)*train_frac) : (int(len(accents_int)*train_frac) + int(len(accents_int)*val_frac))], \n",
        "accents_int[(int(len(accents_int)*train_frac) + int(len(accents_int)*val_frac)):])\n",
        "\n",
        "train_x, val_x, test_x = train_test_val_words(words_int)\n",
        "train_y, val_y, test_y = train_test_val_accents(accents_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXaX9CDxUeC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f5dcccf7-f711-4256-9892-1e7990bcf8a5"
      },
      "source": [
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\t Sizes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\t Sizes:\n",
            "Train set: \t\t(1343301, 30) \n",
            "Validation set: \t(167912, 30) \n",
            "Test set: \t\t(167914, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptlroKTTUeC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "4e08b787-f86b-45e2-e92e-126527240efe"
      },
      "source": [
        "print(\"\\t\\t Vizualization:\")\n",
        "train = ''\n",
        "for i in range(10):\n",
        "    train = ''\n",
        "    for j in range(len(train_x[i])):\n",
        "      if (train_x[i][j] == 0):\n",
        "        break\n",
        "      train = train + chr(train_x[i][j])\n",
        "    print(\"Training set: \",train)\n",
        "for i in range(10):    \n",
        "    vval = ''\n",
        "    for j in range(len(val_x[i])):\n",
        "      if (val_x[i][j] == 0):\n",
        "        break\n",
        "      vval = vval + chr(val_x[i][j])\n",
        "    print(\"Validation set: \",vval)\n",
        "for i in range(10):\n",
        "    test = ''\n",
        "    for j in range(len(test_x[i])):\n",
        "      if (test_x[i][j] == 0):\n",
        "        break\n",
        "      test = test + chr(test_x[i][j])\n",
        "    print(\"Test set: \",test)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t Vizualization:\n",
            "Training set:  а\n",
            "Training set:  аав\n",
            "Training set:  аава\n",
            "Training set:  аавам\n",
            "Training set:  аавами\n",
            "Training set:  аавасакса\n",
            "Training set:  аавах\n",
            "Training set:  ааве\n",
            "Training set:  аавик\n",
            "Training set:  аавов\n",
            "Validation set:  самоокупитесь\n",
            "Validation set:  самоокупится\n",
            "Validation set:  самоокупиться\n",
            "Validation set:  самоокупишься\n",
            "Validation set:  самоокуплюсь\n",
            "Validation set:  самоокупятся\n",
            "Validation set:  самооплодотворение\n",
            "Validation set:  самооплодотворением\n",
            "Validation set:  самооплодотворении\n",
            "Validation set:  самооплодотворений\n",
            "Test set:  трудоустройством\n",
            "Test set:  трудоустройству\n",
            "Test set:  трудоустройся\n",
            "Test set:  трудоустроит\n",
            "Test set:  трудоустроите\n",
            "Test set:  трудоустройте\n",
            "Test set:  трудоустроитесь\n",
            "Test set:  трудоустройтесь\n",
            "Test set:  трудоустроится\n",
            "Test set:  трудоустроить\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sNvLbUDUeC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets for train, test and val\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50 \n",
        "\n",
        "# make sure to SHUFFLE your training data. Keep Shuffle=True.\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDM1Xcv7UeC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b9a9b9a8-210c-4043-af40-854808c744e3"
      },
      "source": [
        "print(type(train_data))\n",
        "print(type(train_x))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.dataset.TensorDataset'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5mQsDPCUeC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3de14c21-40ea-41d4-f545-4f69731d18d6"
      },
      "source": [
        "# obtain one batch of training data and label. \n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 30])\n",
            "Sample input: \n",
            " tensor([[1074, 1082, 1088,  ...,    0,    0,    0],\n",
            "        [1088, 1077, 1081,  ...,    0,    0,    0],\n",
            "        [1074, 1077, 1088,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [1088, 1072, 1079,  ...,    0,    0,    0],\n",
            "        [1088, 1086, 1076,  ...,    0,    0,    0],\n",
            "        [1088, 1072, 1079,  ...,    0,    0,    0]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([ 4,  2,  6,  3,  5,  8,  8,  4,  5,  3,  4, 10,  6,  6,  4,  6,  6,  6,\n",
            "         7,  8,  6,  6,  7,  2,  6,  7,  4, 10,  6,  4,  3, 12,  7,  7,  6,  8,\n",
            "         7,  9,  5,  6,  6,  4,  6,  5,  6,  7,  6,  8,  7,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kWfXfWSUeDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c76ec201-c6d1-42a5-d5c9-d890159b3536"
      },
      "source": [
        "# Check if GPU is available.\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUB3gD5qUeDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, data_len, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "\n",
        "        #Initialize the model by setting up the layers.\n",
        "\n",
        "        super(SentimentLSTM, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(data_len, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "\n",
        "        #Perform a forward pass of our model on some input and hidden state.\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # relu function\n",
        "        relu_out = self.relu(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        relu_out = relu_out.view(batch_size, -1)\n",
        "        relu_out = relu_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last relu output and hidden state\n",
        "        return relu_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        #Initializes hidden state\n",
        "\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnHZMwJYUeDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5a949977-8737-488e-a448-4345c94285e6"
      },
      "source": [
        "# Instantiate the model with these hyperparameters\n",
        "data_len = data_len + 1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(data_len, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(1679128, 300)\n",
            "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpYBjiSpUeDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65VZ5k_GUeDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "e64510e6-8e29-4628-84a7-387f23c51b45"
      },
      "source": [
        "#Training and Validation\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentLSTM(\n",
              "  (embedding): Embedding(1679128, 300)\n",
              "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4beUxKcUeDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ca3c65f4-5e0f-4633-b408-80287b2975d3"
      },
      "source": [
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, acc_position in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, acc_position = inputs.cuda(), acc_position.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ea396717d536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    }
  ]
}